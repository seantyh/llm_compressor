{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if '..' not in sys.path:\n",
    "  sys.path.append('..')\n",
    "\n",
    "import numpy as np\n",
    "from llm_compressor import AECompressorLLM\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"ckiplab/gpt2-base-chinese\")\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "model = AutoModelForCausalLM.from_pretrained(\"ckiplab/gpt2-base-chinese\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:102 for open-end generation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'[CLS] 這 是 一 個 很 好 的 例 子 。 」 他 說 : 「 我 們 不 能 說, 我'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_text = \"這是一個測試\"\n",
    "prompt_ids = tokenizer(\"這是\", return_tensors=\"pt\").input_ids[:, :-1]\n",
    "gentext = tokenizer.batch_decode(\n",
    "            model.generate(input_ids=prompt_ids, \n",
    "            max_new_tokens=20, pad_token_id=tokenizer.eos_token_id))[0]\n",
    "gentext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "input_ids = tokenizer(test_text, return_tensors=\"pt\").input_ids\n",
    "# input_ids = input_ids[:, :-1]\n",
    "with torch.no_grad():\n",
    "  logits = model(input_ids).logits.squeeze()\n",
    "probs = torch.softmax(logits, dim=1)\n",
    "uniform_prob = torch.ones(probs.shape[1]) / probs.shape[1]\n",
    "next_token_probs = torch.concat([uniform_prob.unsqueeze(0), probs[:-1, :]], dim=0)\n",
    "uniform_nt_probs = torch.ones_like(probs) / probs.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([4.7331e-05, 2.4918e-03, 7.1911e-02, 1.1957e-01, 3.2295e-01, 2.2081e-04,\n",
       "        7.3253e-01, 1.9142e-09])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next_token_probs: (seq_len, vocab_size)\n",
    "# input_ids: (batch_size, seq_len)\n",
    "print(input_ids.squeeze().unsqueeze(1).shape)\n",
    "next_token_probs.gather(dim=1, index=input_ids.squeeze().unsqueeze(1)).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "message length: 83 bits\n",
      "data length: 128 bits\n",
      "compress ratio: 0.6484\n"
     ]
    }
   ],
   "source": [
    "compressor = AECompressorLLM()\n",
    "data_ids = input_ids.squeeze().tolist()\n",
    "\n",
    "msg = compressor.compress(data_ids, next_token_probs)\n",
    "recon = compressor.decompress(msg, len(data_ids), next_token_probs)\n",
    "## uniform probs baseline\n",
    "# msg = compressor.compress(data_ids, uniform_nt_probs)\n",
    "# recon = compressor.decompress(msg, len(data_ids), uniform_nt_probs)\n",
    "\n",
    "assert all(a==b for a, b in zip(recon, data_ids))\n",
    "msg_len = len(msg)\n",
    "data_len = len(data_ids) * 16\n",
    "print(f\"message length: {msg_len} bits\")\n",
    "print(f\"data length: {data_len} bits\")\n",
    "print(f\"compress ratio: {msg_len/data_len:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zlib\n",
    "zmsg = zlib.compress(test_text.encode())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(zmsg)/len(test_text.encode())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## clear float2repr implmentation by Copilot\n",
    "import struct\n",
    "\n",
    "def float_repr(num):\n",
    "    # pack the float into a bytes object\n",
    "    packed = struct.pack('f', num)\n",
    "    \n",
    "    # unpack the bytes object to get the exponent and fractional part\n",
    "    bits = struct.unpack('I', packed)[0]    \n",
    "    sign = bits >> 31\n",
    "    exp = (bits >> 23) & 0xff\n",
    "    frac = bits & 0x7fffff\n",
    "    \n",
    "    # convert the exponent to a signed integer\n",
    "    if exp == 0:\n",
    "        exp = -126\n",
    "    else:\n",
    "        exp -= 127\n",
    "    \n",
    "    # convert the fractional part to a float\n",
    "    frac = float(frac) / (1 << 23)\n",
    "    \n",
    "    # apply the sign, exponent, and fractional part to get the final representation\n",
    "    print(\"sign: \", sign)\n",
    "    print(\"exp: \", exp)\n",
    "    print(\"frac: \", frac)\n",
    "    assert (-1)**sign * (1 + frac) * 2**exp == num\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
